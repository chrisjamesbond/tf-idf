{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words that occur nearby frequently are more important than words that only appear once or twice. Yet words that are too frequent — ubiquitous, like \"the\" or \"good\" — are unimportant. How can we balance these two conflicting constraints?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# directory where documents are stored\n",
    "documents_directory = os.path.expanduser('documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets\n",
    "def get_unique_terms_from_document(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    # split document into terms and convert to a set of unique terms\n",
    "    words = text.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_unique_terms(directory):\n",
    "    unique_terms = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            unique_terms.extend(get_unique_terms_from_document(file_path))\n",
    "\n",
    "    unique_terms = set(unique_terms)\n",
    "\n",
    "    return unique_terms\n",
    "\n",
    "unique_terms = get_all_unique_terms(documents_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squash the raw frequency using log10. A word appearing 100 times in a document doesn’t make that word 100 times more likely to be relevant to the meaning of the document. We also need to do something special with counts of 0, since we can’t take the log of 0.\n",
    "\n",
    "$$\n",
    "\\text{tf}_{t,d} =\n",
    "\\begin{cases}\n",
    "1 + \\log_{10}(\\text{count}(t,d)) & \\text{if } \\text{count}(t,d) > 0 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 5\n"
     ]
    }
   ],
   "source": [
    "# we need to get the counts of terms in each document....\n",
    "\n",
    "# term_document_matrix = np.zeros((num_terms, num_documents), dtype=int)\n",
    "\n",
    "# get number of files in /documents\n",
    "\n",
    "# Count the number of files in the directory\n",
    "num_documents = len([name for name in os.listdir(documents_directory) if os.path.isfile(os.path.join(documents_directory, name))])\n",
    "num_terms = len(unique_terms)\n",
    "\n",
    "#term_document_matrix = np.zeros((num_terms, num_documents), dtype=int)\n",
    "\n",
    "#for term in document:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
